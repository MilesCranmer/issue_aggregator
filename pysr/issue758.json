{
  "data": {
    "repository": {
      "issue": {
        "number": 758,
        "title": "[BUG]: Custom loss function not working in multiprocessing-mode",
        "body": "### What happened?\n\nI'm having issues running PySR in multiprocessing mode when I use a custom loss function. My loss function looks like:\r\n\r\n```\r\nfunction eval_loss(tree, dataset::Dataset{T, L}, options::Options, idx)::L where {T, L}\r\n\r\n      # Extract data for the given indices\r\n      x = idx === nothing ? dataset.X : view(dataset.X, :, idx)\r\n      y = idx === nothing ? dataset.y : view(dataset.y, idx)\r\n\r\n      derivative_with_respect_to = 1\r\n      predicted, gradient, complete = eval_diff_tree_array(tree, x, options, derivative_with_respect_to)\r\n      if !complete\r\n          # encountered NaN/Inf, so return early\r\n          return L(Inf)\r\n      end\r\n      # loss components\r\n      positivity = sum(i -> gradient[i] > 0 ? L(0) : abs2(gradient[i]), eachindex(gradient))\r\n      scatter_loss = sum(i -> abs(log((abs(predicted[i])+1e-20) / (abs(y[i])+1e-20))), eachindex(predicted, y))\r\n      sign_loss = sum(i -> 10 * (sign(predicted[i]) - sign(y[i]))^2, eachindex(predicted, y))\r\n      \r\n      beta = L(1e-3)\r\n      return (scatter_loss + sign_loss + beta*positivity) / length(y)\r\n  end\r\n\r\n```\r\nIt works fine when I run it in multithreading mode, but it crashes when trying to use multiprocessing. Grateful for help!\r\n\n\n### Version\n\n1.0.0\n\n### Operating System\n\nmacOS\n\n### Package Manager\n\npip\n\n### Interface\n\nScript (i.e., `python my_script.py`)\n\n### Relevant log output\n\n```shell\nTraceback (most recent call last):\r\n  File \"/Users/isakbe/Dev/modelling/il-sr/il_sr/scripts/run_sr.py\", line 32, in <module>\r\n    main()\r\n  File \"/Users/isakbe/Dev/modelling/il-sr/il_sr/scripts/run_sr.py\", line 23, in main\r\n    trainer.fit_expression()\r\n  File \"/Users/isakbe/Dev/modelling/il-sr/il_sr/scripts/../src/sr_training.py\", line 243, in fit_expression\r\n    self.model.fit(\r\n  File \"/Users/isakbe/Library/Caches/pypoetry/virtualenvs/il-sr-9TFUWRsR-py3.11/lib/python3.11/site-packages/pysr/sr.py\", line 2240, in fit\r\n    self._run(X, y, runtime_params, weights=weights, seed=seed, category=category)\r\n  File \"/Users/isakbe/Library/Caches/pypoetry/virtualenvs/il-sr-9TFUWRsR-py3.11/lib/python3.11/site-packages/pysr/sr.py\", line 2028, in _run\r\n    out = SymbolicRegression.equation_search(\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/isakbe/.julia/packages/PythonCall/Nr75f/src/JlWrap/any.jl\", line 258, in __call__\r\n    return self._jl_callmethod($(pyjl_methodnum(pyjlany_call)), args, kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\njuliacall.JuliaError: On worker 2:\r\nMethodError: no method matching eval_loss(::Node{Float32}, ::Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, ::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5})\r\n\r\nClosest candidates are:\r\n  eval_loss(::Any, ::Dataset{T, L, AX} where AX<:AbstractMatrix{T}, ::Options, !Matched::Any) where {T, L}\r\n   @ Main none:1\r\nStacktrace:\r\n [1] #9\r\n   @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/macros.jl:83\r\n [2] #invokelatest#2\r\n   @ ./essentials.jl:892 [inlined]\r\n [3] invokelatest\r\n   @ ./essentials.jl:889\r\n [4] #107\r\n   @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/process_messages.jl:283\r\n [5] run_work_thunk\r\n   @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/process_messages.jl:70\r\n [6] run_work_thunk\r\n   @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/process_messages.jl:79\r\n [7] #100\r\n   @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/process_messages.jl:88\r\nStacktrace:\r\n  [1] remotecall_fetch(f::Function, w::Distributed.Worker, args::Distributed.RRID; kwargs::@Kwargs{})\r\n    @ Distributed /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/remotecall.jl:465\r\n  [2] remotecall_fetch(f::Function, w::Distributed.Worker, args::Distributed.RRID)\r\n    @ Distributed /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/remotecall.jl:454\r\n  [3] remotecall_fetch\r\n    @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/remotecall.jl:492 [inlined]\r\n  [4] call_on_owner\r\n    @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/remotecall.jl:565 [inlined]\r\n  [5] fetch(r::Distributed.Future)\r\n    @ Distributed /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/remotecall.jl:619\r\n  [6] test_function_on_workers(example_inputs::Tuple{Node{Float32}, Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5}}, op::Function, procs::Vector{Int64})\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/Configure.jl:206\r\n  [7] move_functions_to_workers(procs::Vector{Int64}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5}, dataset::Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, verbosity::Int64)\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/Configure.jl:180\r\n  [8] configure_workers(; procs::Nothing, numprocs::Int64, addprocs_function::typeof(Distributed.addprocs), options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5}, project_path::String, file::String, exeflags::Cmd, verbosity::Int64, example_dataset::Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, runtests::Bool)\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/Configure.jl:349\r\n  [9] _create_workers(datasets::Vector{Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}, ropt::SymbolicRegression.SearchUtilsModule.RuntimeOptions{:multiprocessing, 1, true, SRLogger{TensorBoardLogger.TBLogger{String, IOStream}}}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5})\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:597\r\n [10] _equation_search(datasets::Vector{Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}, ropt::SymbolicRegression.SearchUtilsModule.RuntimeOptions{:multiprocessing, 1, true, SRLogger{TensorBoardLogger.TBLogger{String, IOStream}}}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5}, saved_state::Nothing)\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:532\r\n [11] equation_search(datasets::Vector{Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}; options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5}, saved_state::Nothing, runtime_options::Nothing, runtime_options_kws::@Kwargs{niterations::Int64, parallelism::String, numprocs::Int64, procs::Nothing, addprocs_function::Nothing, heap_size_hint_in_bytes::Nothing, runtests::Bool, return_state::Bool, run_id::String, verbosity::Int64, logger::SRLogger{TensorBoardLogger.TBLogger{String, IOStream}}, progress::Bool, v_dim_out::Val{1}})\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:525\r\n [12] equation_search\r\n    @ ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:506 [inlined]\r\n [13] #equation_search#20\r\n    @ ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:476 [inlined]\r\n [14] equation_search\r\n    @ ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:422 [inlined]\r\n [15] #equation_search#21\r\n    @ ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:499 [inlined]\r\n [16] pyjlany_call(self::typeof(equation_search), args_::Py, kwargs_::Py)\r\n    @ PythonCall.JlWrap ~/.julia/packages/PythonCall/Nr75f/src/JlWrap/any.jl:40\r\n [17] _pyjl_callmethod(f::Any, self_::Ptr{PythonCall.C.PyObject}, args_::Ptr{PythonCall.C.PyObject}, nargs::Int64)\r\n    @ PythonCall.JlWrap ~/.julia/packages/PythonCall/Nr75f/src/JlWrap/base.jl:73\r\n [18] _pyjl_callmethod(o::Ptr{PythonCall.C.PyObject}, args::Ptr{PythonCall.C.PyObject})\r\n    @ PythonCall.JlWrap.Cjl ~/.julia/packages/PythonCall/Nr75f/src/JlWrap/C.jl:63\n```\n\n\n### Extra Info\n\n_No response_",
        "comments": {
          "nodes": [
            {
              "author": {
                "login": "MilesCranmer"
              },
              "body": "Hm. What happens if you give it a different name? Like `my_eval_loss`?",
              "createdAt": "2024-12-02T12:12:12Z"
            },
            {
              "author": {
                "login": "ibengtsson"
              },
              "body": "Same issue if I change the name to `my_eval_loss` unfortunately.",
              "createdAt": "2024-12-02T12:26:10Z"
            },
            {
              "author": {
                "login": "MilesCranmer"
              },
              "body": "Does it work with `batching=false` and no `idx` argument?\r\n\r\nCan you also try modifying the signature like\r\n\r\n```julia\r\nfunction eval_loss(tree, dataset::Dataset{T, L}, options::Options, idx=nothing)::L where {T, L}\r\n```\r\n\r\nNote the `idx=nothing`. \r\n\r\nThe specific error complains there is no method for `::Node, ::Dataset, ::Options`, which is true here. But I'm confused that it worked in normal multithreading mode but not on workers.",
              "createdAt": "2024-12-02T12:54:48Z"
            },
            {
              "author": {
                "login": "MilesCranmer"
              },
              "body": "Also can you share the error traceback when you name it `my_eval_loss`?",
              "createdAt": "2024-12-02T12:57:06Z"
            },
            {
              "author": {
                "login": "ibengtsson"
              },
              "body": "So it seems that setting `idx=nothing` works! It also works when you set `batching=False` and don't use a `idx` argument. \r\n\r\nFor completeness, here's my output for naming the function `my_eval_loss`. \r\n<details open>\r\n<summary>Output</summary>\r\n<br>\r\nTraceback (most recent call last):\r\n  File \"/Users/isakbe/Dev/modelling/il-sr/il_sr/scripts/run_sr.py\", line 32, in <module>\r\n    main()\r\n  File \"/Users/isakbe/Dev/modelling/il-sr/il_sr/scripts/run_sr.py\", line 23, in main\r\n    trainer.fit_expression()\r\n  File \"/Users/isakbe/Dev/modelling/il-sr/il_sr/scripts/../src/sr_training.py\", line 245, in fit_expression\r\n    self.model.fit(\r\n  File \"/Users/isakbe/Library/Caches/pypoetry/virtualenvs/il-sr-9TFUWRsR-py3.11/lib/python3.11/site-packages/pysr/sr.py\", line 2240, in fit\r\n    self._run(X, y, runtime_params, weights=weights, seed=seed, category=category)\r\n  File \"/Users/isakbe/Library/Caches/pypoetry/virtualenvs/il-sr-9TFUWRsR-py3.11/lib/python3.11/site-packages/pysr/sr.py\", line 2028, in _run\r\n    out = SymbolicRegression.equation_search(\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/isakbe/.julia/packages/PythonCall/Nr75f/src/JlWrap/any.jl\", line 258, in __call__\r\n    return self._jl_callmethod($(pyjl_methodnum(pyjlany_call)), args, kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\njuliacall.JuliaError: On worker 2:\r\nMethodError: no method matching my_eval_loss(::Node{Float32}, ::Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, ::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5})\r\n\r\nClosest candidates are:\r\n  my_eval_loss(::Any, ::Dataset{T, L, AX} where AX<:AbstractMatrix{T}, ::Options, !Matched::Any) where {T, L}\r\n   @ Main none:1\r\n\r\nStacktrace:\r\n [1] #9\r\n   @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/macros.jl:83\r\n [2] #invokelatest#2\r\n   @ ./essentials.jl:892 [inlined]\r\n [3] invokelatest\r\n   @ ./essentials.jl:889\r\n [4] #107\r\n   @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/process_messages.jl:283\r\n [5] run_work_thunk\r\n   @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/process_messages.jl:70\r\n [6] run_work_thunk\r\n   @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/process_messages.jl:79\r\n [7] #100\r\n   @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/process_messages.jl:88\r\nStacktrace:\r\n  [1] remotecall_fetch(f::Function, w::Distributed.Worker, args::Distributed.RRID; kwargs::@Kwargs{})\r\n    @ Distributed /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/remotecall.jl:465\r\n  [2] remotecall_fetch(f::Function, w::Distributed.Worker, args::Distributed.RRID)\r\n    @ Distributed /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/remotecall.jl:454\r\n  [3] remotecall_fetch\r\n    @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/remotecall.jl:492 [inlined]\r\n  [4] call_on_owner\r\n    @ /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/remotecall.jl:565 [inlined]\r\n  [5] fetch(r::Distributed.Future)\r\n    @ Distributed /opt/homebrew/Cellar/julia/1.10.4/share/julia/stdlib/v1.10/Distributed/src/remotecall.jl:619\r\n  [6] test_function_on_workers(example_inputs::Tuple{Node{Float32}, Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5}}, op::Function, procs::Vector{Int64})\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/Configure.jl:206\r\n  [7] move_functions_to_workers(procs::Vector{Int64}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5}, dataset::Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, verbosity::Int64)\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/Configure.jl:180\r\n  [8] configure_workers(; procs::Nothing, numprocs::Int64, addprocs_function::typeof(Distributed.addprocs), options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5}, project_path::String, file::String, exeflags::Cmd, verbosity::Int64, example_dataset::Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}, runtests::Bool)\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/Configure.jl:349\r\n  [9] _create_workers(datasets::Vector{Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}, ropt::SymbolicRegression.SearchUtilsModule.RuntimeOptions{:multiprocessing, 1, true, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5})\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:597\r\n [10] _equation_search(datasets::Vector{Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}, ropt::SymbolicRegression.SearchUtilsModule.RuntimeOptions{:multiprocessing, 1, true, Nothing}, options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5}, saved_state::Nothing)\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:532\r\n [11] equation_search(datasets::Vector{Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, @NamedTuple{}, Nothing, Nothing, Nothing, Nothing}}; options::Options{SymbolicRegression.CoreModule.OptionsStructModule.ComplexityMapping{Int64, Int64}, DynamicExpressions.OperatorEnumModule.OperatorEnum, Node, Expression, @NamedTuple{}, MutationWeights, false, true, nothing, Nothing, 5}, saved_state::Nothing, runtime_options::Nothing, runtime_options_kws::@Kwargs{niterations::Int64, parallelism::String, numprocs::Int64, procs::Nothing, addprocs_function::Nothing, heap_size_hint_in_bytes::Nothing, runtests::Bool, return_state::Bool, run_id::String, verbosity::Int64, logger::Nothing, progress::Bool, v_dim_out::Val{1}})\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:525\r\n [12] equation_search\r\n    @ ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:506 [inlined]\r\n [13] #equation_search#20\r\n    @ ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:476 [inlined]\r\n [14] equation_search\r\n    @ ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:422 [inlined]\r\n [15] #equation_search#21\r\n    @ ~/.julia/packages/SymbolicRegression/44X04/src/SymbolicRegression.jl:499 [inlined]\r\n [16] pyjlany_call(self::typeof(equation_search), args_::Py, kwargs_::Py)\r\n    @ PythonCall.JlWrap ~/.julia/packages/PythonCall/Nr75f/src/JlWrap/any.jl:40\r\n [17] _pyjl_callmethod(f::Any, self_::Ptr{PythonCall.C.PyObject}, args_::Ptr{PythonCall.C.PyObject}, nargs::Int64)\r\n    @ PythonCall.JlWrap ~/.julia/packages/PythonCall/Nr75f/src/JlWrap/base.jl:73\r\n [18] _pyjl_callmethod(o::Ptr{PythonCall.C.PyObject}, args::Ptr{PythonCall.C.PyObject})\r\n    @ PythonCall.JlWrap.Cjl ~/.julia/packages/PythonCall/Nr75f/src/JlWrap/C.jl:63\r\n</details>\r\n\r\nThank you so much for the quick help!",
              "createdAt": "2024-12-02T13:12:12Z"
            },
            {
              "author": {
                "login": "MilesCranmer"
              },
              "body": "Cool! Thanks. And just to check, what happens in multithreading mode when you use the original function string, but rename it to `my_eval_loss`?\r\n\r\nI think it's some unfortunate combination of it being a real error (not setting `idx=nothing` in a custom loss function) but multithreading mode it was colliding with the internal function of the same name (also `eval_loss`). Which is why it only seemed to hit this error in multiprocessing only.\r\n\r\nI guess on my side I should add an error check for the function name not being equal to `eval_loss`, and also helpful error messages if `idx` is not given a default of `nothing`.",
              "createdAt": "2024-12-02T13:34:13Z"
            },
            {
              "author": {
                "login": "MilesCranmer"
              },
              "body": "Btw, do you remember if there was any documentation which incorrectly suggested `idx)` instead of `idx=nothing)` in a custom loss function? I want to update that too.",
              "createdAt": "2024-12-02T13:39:59Z"
            },
            {
              "author": {
                "login": "ibengtsson"
              },
              "body": "If I rename the function string and use multithreading it actually works too. Not really sure why... \r\n\r\nHmm, regarding documentation I'm not sure! I have limited experience with Julia so I pieced together quite many different discussion replies to make it (sort of...) work. I think it comes down to me not really knowing Julia and that the documentation only shows how to write a custom loss function for the case of no batching! ",
              "createdAt": "2024-12-02T13:57:44Z"
            },
            {
              "author": {
                "login": "MilesCranmer"
              },
              "body": "Cool. Thanks for helping get more debug info for this!",
              "createdAt": "2024-12-02T13:59:34Z"
            }
          ],
          "pageInfo": {
            "hasNextPage": false,
            "endCursor": "Y3Vyc29yOnYyOpHOlbRNiw=="
          }
        }
      }
    }
  }
}
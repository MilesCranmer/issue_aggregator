{
  "data": {
    "repository": {
      "discussion": {
        "number": 773,
        "title": "Monotonicity check within TemplateExpression and general efficiency improvements",
        "body": "This is a continuation of #767 \r\nMainly surrounding: derivates within TemplateExpression, Miles has a found an elegant solution to higher order derivates. \r\nI had two main questions: \r\n1) Although D works great for single variable derivates, what is the most efficient way to conduct monotonicity checks within a structure for a TemplateExpression\r\n. \r\nhttps://github.com/MilesCranmer/PySR/discussions/767#discussioncomment-11508707\r\n> I think you could potentially use `eval_grad_tree_array` within the TemplateStructure though I haven't tried. You can extract the tree with `DE.get_tree(f)` (where `DE` is `DynamicExpressions`)[1](#user-content-fn-1-2ec381930be3c9598772db4f4bec1e67) and then `DE.get_operators(f)` to get the operators[2](#user-content-fn-2-2ec381930be3c9598772db4f4bec1e67). Then the call is:\r\n> \r\n> ```julia\r\n> tree = DE.get_tree(f)\r\n> operators = DE.get_operators(f)\r\n> X = stack((x1.x, x2.x, #= ... =#), dims=1)\r\n> result, grad, complete = eval_grad_tree_array(tree, X, operators)\r\n> ```\r\n> \r\n> ## Footnotes\r\n> 1. All it's doing is calling `f.tree`. The reason to prefer the `get_tree` is that it's more general in case there is some other type of expression used here in the future. [↩](#user-content-fnref-1-2ec381930be3c9598772db4f4bec1e67)\r\n> 2. All it is doing is calling `f.metadata.operators`. [↩](#user-content-fnref-2-2ec381930be3c9598772db4f4bec1e67)\r\n\r\n[](url)\r\n\r\nI've done this so far: \r\n```julia\r\nusing DynamicDiff: DynamicDiff as DA\r\nusing DynamicExpressions: DynamicExpressions as DE\r\nusing SymbolicRegression.TemplateExpressionModule: ArgumentRecorder\r\nDA.D(f::ArgumentRecorder, _::Integer) = f\r\n# Example structure with monotonicity checks for multiple variables (x1, x2, x3, x4, x5)\r\nstructure = TemplateStructure{(:f,)}(\r\n  ((; f), (x1, x2, x3, x4, x5, x6, y, category)) -> begin\r\n    o = f(x1, x2, x3, x4, x5, x6)\r\n    if !o.valid\r\n        return ValidVector(fill(1e9, length(o.x)), false)\r\n    end\r\n    tree = DE.get_tree(f.tree)\r\n    operators = DE.get_operators(f)\r\n    X = stack((x1.x, x2.x, x3.x, x4.x, x5.x), dims=1)\r\n    result, grad, complete = eval_grad_tree_array(tree, X, operators) #...continuation of code\r\n```\r\n\r\nHowever,  neither get_tree (f) or get_operators(f) work. \r\n```julia\r\nERROR: type ArgumentRecorder has no field tree\r\n...\r\n(ERROR: MethodError: no method matching get_operators(::ArgumentRecorder{Compat.Fix{1, Compat.Fix{1, typeof(SymbolicRegression.TemplateExpressionModule._record_composable_expression!), @NamedTuple{f::Base.RefValue{Int64}}}, Val{:f}}}))\r\n```\r\n\r\n2) Users may standardise their variables on input, but domain knowledge means that those functions are unlikely to work with standardised variables. The workaround for me has been to feed in the variables I need as non-standardised variables:\r\n```julia\r\n((; f), (x1, x2, x3, x4, x5, x6, y, category,x1_NS,x2_NS,x3_NS)) -> begin #NonStandardised\r\n```\r\nthen using the _NS variables within the evaluation. This works, but I suppose is not memory efficient. I was wondering if you had any suggestions regarding that aspect? Essentially, you could replace a custom loss function into structure, instead of calling on global variables etc.\r\n\r\nThank you! The problem is now I am obsessing about getting this code efficient and losing sight of the actual problem!\r\n\r\nEDIT: After lots of trouble shooting, D() generally works as fast as eval_grad_tree_array and so it was not necessary to get it to work. And feeding in extra variables did not seem to negatively affect performance, only what was fed through the functions. ",
        "comments": {
          "nodes": [],
          "pageInfo": {
            "hasNextPage": false,
            "endCursor": null
          }
        }
      }
    }
  }
}
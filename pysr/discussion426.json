{
  "data": {
    "repository": {
      "discussion": {
        "number": 426,
        "title": "Can I add roll as a custom unary operator",
        "body": "Hi! Forgive me if my question is dumb - am very new to `PySR` and `julia`!\r\n\r\nI would like to implement a custom unary operator `roll`, with something like below:\r\n\r\n```python\r\n        unary_operators=[\r\n            \"roll(x) = vcat(x[end:end], x[1:end - 1])\",\r\n        ],\r\n```\r\n\r\nBasically I tried to implement the roll function in julia (implemented with `vcat`).\r\n\r\nThis run into errors:\r\n\r\n```\r\nRuntimeError: <PyCall.jlwrap (in a Julia function called from Python)\r\nJULIA: The operator `cf` is not well-defined over the real line, as it threw the error `MethodError` when evaluating the input -100.0. You can work around this by returning NaN for invalid inputs. For example, `safe_log(x::T) where {T} = x > 0 ? log(x) : T(NaN)`.\r\nStacktrace:\r\n  [1] error(s::String)\r\n    @ Base ./error.jl:35\r\n  [2] test_operator(op::typeof(cf), x::Float32, y::Nothing)\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/XKtla/src/Configure.jl:8\r\n  [3] test_operator(op::typeof(cf), x::Float32)\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/XKtla/src/Configure.jl:4\r\n  [4] assert_operators_well_defined(T::Type, options::Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}})\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/XKtla/src/Configure.jl:42\r\n  [5] test_option_configuration(T::Type, options::Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}})\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/XKtla/src/Configure.jl:58\r\n  [6] _equation_search(#unused#::Val{:multithreading}, #unused#::Val{1}, datasets::Vector{Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(), Tuple{}}, Nothing, Nothing, Nothing, Nothing}}, niterations::Int64, options::Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}, numprocs::Nothing, procs::Nothing, addprocs_function::Nothing, runtests::Bool, saved_state::Nothing, verbosity::Int64, progress::Bool, #unused#::Val{true})\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/XKtla/src/SymbolicRegression.jl:566\r\n  [7] equation_search(datasets::Vector{Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(), Tuple{}}, Nothing, Nothing, Nothing, Nothing}}; niterations::Int64, options::Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}, parallelism::String, numprocs::Nothing, procs::Nothing, addprocs_function::Nothing, runtests::Bool, saved_state::Nothing, return_state::Bool, verbosity::Int64, progress::Bool, v_dim_out::Val{1})\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/XKtla/src/SymbolicRegression.jl:507\r\n  [8] equation_search(X::Matrix{Float32}, y::Matrix{Float32}; niterations::Int64, weights::Nothing, options::Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}, variable_names::Vector{String}, display_variable_names::Vector{String}, y_variable_names::Nothing, parallelism::String, numprocs::Nothing, procs::Nothing, addprocs_function::Nothing, runtests::Bool, saved_state::Nothing, return_state::Bool, loss_type::Type{Nothing}, verbosity::Int64, progress::Bool, X_units::Nothing, y_units::Nothing, v_dim_out::Val{1}, multithreaded::Nothing, varMap::Nothing)\r\n    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/XKtla/src/SymbolicRegression.jl:385\r\n  [9] equation_search\r\n    @ ~/.julia/packages/SymbolicRegression/XKtla/src/SymbolicRegression.jl:330 [inlined]\r\n [10] #equation_search#24\r\n    @ ~/.julia/packages/SymbolicRegression/XKtla/src/SymbolicRegression.jl:414 [inlined]\r\n [11] invokelatest(::Any, ::Any, ::Vararg{Any}; kwargs::Base.Pairs{Symbol, Any, NTuple{15, Symbol}, NamedTuple{(:weights, :niterations, :variable_names, :display_variable_names, :y_variable_names, :X_units, :y_units, :options, :numprocs, :parallelism, :saved_state, :return_state, :addprocs_function, :progress, :verbosity), Tuple{Nothing, Int64, Vector{String}, Vector{String}, Nothing, Nothing, Nothing, Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}, Nothing, String, Nothing, Bool, Nothing, Bool, Int64}}})\r\n    @ Base ./essentials.jl:818\r\n [12] _pyjlwrap_call(f::Function, args_::Ptr{PyCall.PyObject_struct}, kw_::Ptr{PyCall.PyObject_struct})\r\n    @ PyCall ~/.julia/packages/PyCall/ilqDX/src/callback.jl:32\r\n [13] pyjlwrap_call(self_::Ptr{PyCall.PyObject_struct}, args_::Ptr{PyCall.PyObject_struct}, kw_::Ptr{PyCall.PyObject_struct})\r\n    @ PyCall ~/.julia/packages/PyCall/ilqDX/src/callback.jl:44>\r\n```\r\n\r\nI know that what I am doing is probably wrong. My questions is actually whether this is achievable. If so, how to do that?\r\n\r\nThanks!",
        "comments": {
          "nodes": [
            {
              "author": {
                "login": "MilesCranmer"
              },
              "body": "Hi @breakds,\r\n\r\nAll operators are only defined on 1 or 2 real numbers. So you cannot, by default, define operators on vectors like in your example.\r\n\r\nHowever, this is possible by writing your own custom evaluation scheme. Take a look at https://astroautomata.com/PySR/api/#the-objective for an example, and also https://astroautomata.com/PySR/backend/ for info about customizing behavior.\r\n\r\nYou would essentially need to write a custom `eval_tree_array` that can handle `roll`. \r\n\r\nBasically, you would edit `_eval_tree_array` in DynamicExpressions.jl to be (copying from https://github.com/SymbolicML/DynamicExpressions.jl/blob/46388518281b0be12479afcb3a3b8bdabc361ccd/src/EvaluateEquation.jl and then simplifying)\r\n\r\n```julia\r\nfunction _eval_tree_array(\r\n    tree::Node{T}, cX::AbstractMatrix{T}, operators::OperatorEnum, ::Val{turbo}\r\n)::Tuple{AbstractVector{T},Bool} where {T<:Number,turbo}\r\n    # First, we see if there are only constants in the tree - meaning\r\n    # we can just return the constant result.\r\n    if tree.degree == 0\r\n        return deg0_eval(tree, cX)\r\n    elseif tree.degree == 1\r\n        op = operators.unaops[tree.op]\r\n        # op(x), for any x.\r\n        (cumulator, complete) = _eval_tree_array(tree.l, cX, operators, Val(turbo))\r\n        @return_on_false complete cumulator\r\n        @return_on_nonfinite_array cumulator\r\n        return deg1_eval(cumulator, op, Val(turbo))\r\n    elseif tree.degree == 2\r\n        op = operators.binops[tree.op]\r\n        (cumulator_l, complete) = _eval_tree_array(tree.l, cX, operators, Val(turbo))\r\n        @return_on_false complete cumulator_l\r\n        @return_on_nonfinite_array cumulator_l\r\n        (cumulator_r, complete) = _eval_tree_array(tree.r, cX, operators, Val(turbo))\r\n        @return_on_false complete cumulator_r\r\n        @return_on_nonfinite_array cumulator_r\r\n        # op(x, y), for any x or y\r\n        return deg2_eval(cumulator_l, cumulator_r, op, Val(turbo))\r\n    end\r\nend\r\n```\r\n\r\nand then write a custom `deg1_eval` for your roll operator, like this (add somewhere in SymbolicRegression.jl)\r\n\r\n```julia\r\nimport DynamicExpressions.EvaluateEquationModule: deg1_eval\r\n\r\n# Add an additional method to `deg1_eval` to customize the behavior for roll:\r\nfunction deg1_eval(cumulator::AbstractVector{T}, ::typeof(roll), ::Val{turbo}) where {T<:Number,turbo}\r\n    cumulator = roll(cumulator)\r\n    return (cumulator, true)\r\nend\r\n```\r\n\r\nThis is needed because the normal `deg1_eval` is just per-element: https://github.com/SymbolicML/DynamicExpressions.jl/blob/46388518281b0be12479afcb3a3b8bdabc361ccd/src/EvaluateEquation.jl#L152-L160.\r\n\r\n```julia\r\nroll(x) = vcat(x[end:end], x[1:end - 1])\r\n```\r\n\r\nIn Julia you can write specialized methods for particular types of arguments. In this case `typeof(roll)` is the argument we are specializing `deg1_eval` to.\r\n\r\n",
              "createdAt": "2023-09-17T10:59:28Z"
            },
            {
              "author": {
                "login": "breakds"
              },
              "body": "Thanks a lot for the prompt response, @MilesCranmer !\r\n\r\nSeems that after running `julia.install()` and `pysr.install()`, the julia packages are now at `~/.julia/packages`. Do you suggest directly editing the `DynamicExpression` and `SymbolicRegression` there? Or maybe there is a more systematic way so that I can specify (customized) versions of those packages and run `install()` again?\r\n\r\nAppreciate your help!",
              "createdAt": "2023-09-17T17:17:32Z"
            },
            {
              "author": {
                "login": "Shashank19git"
              },
              "body": "HI @breakds ,\r\nwere you able to implement it successfully? \r\nI want to define derivative operator using finite difference.\r\nThanks.",
              "createdAt": "2025-02-27T15:49:09Z"
            }
          ],
          "pageInfo": {
            "hasNextPage": false,
            "endCursor": "Y3Vyc29yOnYyOpK5MjAyNS0wMi0yN1QxNTo0OTowOSswMDowMM4AvE7H"
          }
        }
      }
    }
  }
}